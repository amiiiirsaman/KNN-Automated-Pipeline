{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings['distance'] = dc_listings['accommodates'].apply(lambda x: np.abs(x - new_listing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dc_listings[dc_listings[\"distance\"] == 0][\"accommodates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "dc_listings = dc_listings.sort_values('distance')\n",
    "print(dc_listings.iloc[0:10]['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "mean_price = dc_listings[0:5]['price'].mean()\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x-new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    x = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = x.mean()\n",
    "    return(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['accommodates'].apply(predict_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_df['error'] = np.absolute(test_df['predicted_price'] - test_df['price'])\n",
    "mae = test_df['error'].mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors_prices.mean()\n",
    "    return(predicted_price)\n",
    "test_df['predicted_price'] = test_df['bathrooms'].apply(predict_price)\n",
    "\n",
    "test_df['errorof'] = (test_df['predicted_price'] - test_df['price'])**2\n",
    "mse = test_df['errorof'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))\n",
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "rmse = mse**(0.5)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_acceptance_rate', 'host_listings_count', 'host_response_rate']\n",
    "dc_listings = dc_listings.drop(drop_columns, axis = 1)\n",
    "print (dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = dc_listings.drop(['cleaning_fee', 'security_deposit'], axis=1)\n",
    "dc_listings = dc_listings.dropna(axis=0)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_transform = dc_listings['maximum_nights'] - dc_listings['maximum_nights'].mean()\n",
    "# Divide each value in the column by the standard deviation.\n",
    "normalized_col = first_transform / first_transform.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing = normalized_listings.iloc[4][['accommodates', 'bathrooms']]\n",
    "first_fifth_distance = distance.euclidean(first_listing, fifth_listing)\n",
    "print(first_fifth_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn library is the most popular machine learning library in Python\n",
    "\n",
    "The scikit-learn workflow consists of 4 main steps:\n",
    "\n",
    "    •\tinstantiate the specific machine learning model you want to use\n",
    "\n",
    "    •\tfit the model to the training data\n",
    "\n",
    "    •\tuse the model to make predictions\n",
    "\n",
    "    •\tevaluate the accuracy of the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tn_neighbors: the number of neighbors, is set to 5\n",
    "\n",
    "•\talgorithm: for computing nearest neighbors, is set to auto\n",
    "\n",
    "•\tp: set to 2, corresponding to Euclidean distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full dataset into train and test sets.\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "# Matrix-like object, containing just the 2 columns of interest from training set.\n",
    "train_features = train_df[['accommodates', 'bathrooms']]\n",
    "# List-like object, containing just the target column, `price`.\n",
    "train_target = train_df['price']\n",
    "# Pass everything into the fit method.\n",
    "knn.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(test_df[['accommodates', 'bathrooms']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(algorithm = 'brute')\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "\n",
    "train_features = train_df[['accommodates', 'bathrooms']]\n",
    "train_target = train_df['price']\n",
    "\n",
    "knn.fit(train_features, train_target)\n",
    "\n",
    "predictions = knn.predict(test_df[['accommodates', 'bathrooms']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a model using the following 4 features:\n",
    "\n",
    "•\taccommodates\n",
    "\n",
    "•\tbedrooms\n",
    "\n",
    "•\tbathrooms\n",
    "\n",
    "•\tnumber_of_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "four_predictions = knn.predict(test_df[features])\n",
    "four_mse = mean_squared_error(test_df['price'], four_predictions)\n",
    "four_rmse = four_mse**(1/2)\n",
    "print(four_mse)\n",
    "print(four_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take this to the extreme and use all of the potential features. \n",
    "#We should expect the error scores to decrease since so far adding more features has helped do so.\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[features])\n",
    "all_features_mse = mean_squared_error(test_df['price'], all_features_predictions)\n",
    "all_features_rmse = all_features_mse ** (1/2)\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "•\tSelecting a subset of the possible hyperparameter values\n",
    "\n",
    "•\tTraining a model using each of these hyperparameter values\n",
    "\n",
    "•\tEvaluating each model's performance\n",
    "\n",
    "•\tSelecting the hyperparameter value that resulted in the lowest error value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "hyper_params = [1,2,3,4,5]\n",
    "mse_values = []\n",
    "for x in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=x, algorithm='brute')\n",
    "    features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "print(mse_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In holdout validation, we usually use a 50/50 split instead of the 75/25 split from train/test validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code locally in Jupyter Notebook or Jupyter Lab without .copy(), you'll notice what is known as a SettingWithCopy Warning. This won't prevent your code from running properly, but it's letting you know that whatever operation you're doing is trying to be set on a copy of a slice from a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "shuffled_index = np.random.permutation(dc_listings.index)\n",
    "dc_listings = dc_listings.reindex(shuffled_index)\n",
    "\n",
    "split_one = dc_listings.iloc[0:1862].copy()\n",
    "split_two = dc_listings.iloc[1862:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "# First half\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(train_one[[\"accommodates\"]], train_one[\"price\"])\n",
    "test_one[\"predicted_price\"] = model.predict(test_one[[\"accommodates\"]])\n",
    "iteration_one_rmse = mean_squared_error(test_one[\"price\"], test_one[\"predicted_price\"])**(1/2)\n",
    "\n",
    "# Second half\n",
    "model.fit(train_two[[\"accommodates\"]], train_two[\"price\"])\n",
    "test_two[\"predicted_price\"] = model.predict(test_two[[\"accommodates\"]])\n",
    "iteration_two_rmse = mean_squared_error(test_two[\"price\"], test_two[\"predicted_price\"])**(1/2)\n",
    "\n",
    "avg_rmse = np.mean([iteration_two_rmse, iteration_one_rmse])\n",
    "\n",
    "print(iteration_one_rmse, iteration_two_rmse, avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tsplitting the full dataset into k equal length partitions.\n",
    "\n",
    " o\tselecting k-1 partitions as the training set and\n",
    "\n",
    " o\tselecting the remaining partition as the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of splitting into 5 dataframes, let's add a column that specifies which fold the row belongs to. \n",
    "\n",
    "dc_listings.loc[dc_listings.index[0:745], \"fold\"] = 1\n",
    "dc_listings.loc[dc_listings.index[745:1490], \"fold\"] = 2\n",
    "dc_listings.loc[dc_listings.index[1490:2234], \"fold\"] = 3\n",
    "dc_listings.loc[dc_listings.index[2234:2978], \"fold\"] = 4\n",
    "dc_listings.loc[dc_listings.index[2978:3723], \"fold\"] = 5\n",
    "\n",
    "print(dc_listings['fold'].value_counts())\n",
    "print(\"\\n Num of missing values: \", dc_listings['fold'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by performing the first iteration of k-fold cross validation on a simple, univariate model.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Training\n",
    "model = KNeighborsRegressor()\n",
    "train_iteration_one = dc_listings[dc_listings[\"fold\"] != 1]\n",
    "test_iteration_one = dc_listings[dc_listings[\"fold\"] == 1].copy()\n",
    "model.fit(train_iteration_one[[\"accommodates\"]],\n",
    "          train_iteration_one[\"price\"])\n",
    "\n",
    "labels = model.predict(test_iteration_one[[\"accommodates\"]])\n",
    "test_iteration_one[\"predicted_price\"] = labels\n",
    "iteration_one_mse = mean_squared_error(test_iteration_one[\"price\"], test_iteration_one[\"predicted_price\"])\n",
    "iteration_one_rmse = iteration_one_mse ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fold_ids = [1,2,3,4,5]\n",
    "def train_and_validate(df, folds):\n",
    "    fold_rmses = []\n",
    "    for fold in folds:\n",
    "        # Train\n",
    "        model = KNeighborsRegressor()\n",
    "        train = df[df[\"fold\"] != fold]\n",
    "        test = df[df[\"fold\"] == fold].copy()\n",
    "        model.fit(train[[\"accommodates\"]], train[\"price\"])\n",
    "        # Predict\n",
    "        labels = model.predict(test[[\"accommodates\"]])\n",
    "        test[\"predicted_price\"] = labels\n",
    "        mse = mean_squared_error(test[\"price\"], test[\"predicted_price\"])\n",
    "        rmse = mse**(1/2)\n",
    "        fold_rmses.append(rmse)\n",
    "    return(fold_rmses)\n",
    "\n",
    "rmses = train_and_validate(dc_listings, fold_ids)\n",
    "print(rmses)\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large amount of variability between the RMSE values means that we're either using \n",
    "# a poor model or a poor evaluation criteria (or a bit of both!). \n",
    "# To build a better k-nearest neighbors model, \n",
    "# we can change the features it uses or tweak the number of neighbors (a hyperparameter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(estimator, X, Y, scoring=None, cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(5, shuffle=True, random_state=1)\n",
    "model = KNeighborsRegressor()\n",
    "mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "rmses = np.sqrt(np.absolute(mses))\n",
    "avg_rmse = np.mean(rmses)\n",
    "\n",
    "print(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation, or LOOCV for short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]\n",
    "\n",
    "for fold in num_folds:\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    std_rmse = np.std(rmses)\n",
    "    print(str(fold), \"folds: \", \"avg RMSE: \", str(avg_rmse), \"std RMSE: \", str(std_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
